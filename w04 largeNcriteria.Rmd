---
title: "Research design"
subtitle: "and causal inference"
author: "Austin Hart"
institute: "American University"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, rladies, rladies-fonts]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  message=FALSE, warning=FALSE, echo = FALSE, 
  fig.width=3, fig.height=2, fig.align = 'center'
)
```

```{r results='hide', message=FALSE, warning=FALSE, eval=TRUE}
library(tidyverse)
library(magrittr)
```

## Key terms for the day

- **CAUSAL INFERENCE**: The attribution of an effect/outcome to a cause based on the evidence presented.

- **STATISTICS**: Science of analyzing data collected over a large number of observations.

- **INTERNAL VALIDITY**: Extent to which evidence presented supports a causal claim.  
i.e. can eliminate alternative explanations, biases, etc., for a finding. 

- **RESEARCH DESIGN**: Strategy for answering an empirical question. It determines how you collect and analyze data.


---
class: inverse, center, middle

# Assessing internal validity
### Is that inference justified?

---

# Criteria for causal inference

Given the argument that A is causing B:

- Is there **evidence that A and B are correlated**?

- Is there a **credible causal mechanism** linking A to B?

- Can you **rule out bias from reverse causality**, i.e., that B is causing A?

- Can you **rule out bias due to confounders**, or does A share a common cause with B that makes the relationship spurious?


---

# Hurdle 1: correlation

Is there statistical evidence that A is systematically correlated with B?

- **WHO CARES?** Without it, all you have is an assertion. 
- **WHAT TO LOOK FOR:** Evidence that A and B 'move together'  

  > "Risk of heart attack among vegetarians was 13% lower than among meat eaters"
    
- **RAISING THE ALARM:**  

  > "The study fails to show that A and B are related at all. There is no empirical basis for inferring that A is causing B."  


---

# Hurdle 2: causal mechanism

Is there a plausible reason why exposure to A would cause a response in B?

- **WHO CARES?** Without it, covariation b/w A and B may be coincidental.
- **WHAT TO LOOK FOR:** Simple explanation

  > "Vegetarian diet is lower in saturated fats which tend to create the blockages that lead to heart attacks"
  
- **RAISING THE ALARM:** 

  > "Without a plausible explanation as to how A would cause B, we cannot rule out the possibility that the observed association is purely coincidental."


---

# Hurdle 3: bias from reverse causality

Given the claim that A is causing B, can you rule out the opposite interpretation: that B is causing A?

- **WHO CARES?** If not, you cannot distinguish cause from effect.
- **WHAT TO LOOK FOR:** Evidence that A *precedes* change in B.

  > "Those switching to vegetarian diet saw a 10% reduction in all cause deaths in the first year."
  
- **RAISING THE ALARM:**

  > "We cannot rule out the reverse causal claim that B is the cause of A."  

---

# Hurdle 4: confounding/selection bias

Can you **rule out confounding variables**, or do exposure (A) and outcome (B) share a common cause?

- **WHO CARES?** Violates "independence" assumption; renders association b/w A and B spurious
- **WHAT TO LOOK FOR:** Clear evidence of controlling for, conditioning on, factors that differentiate groups of A.  

  > "The analysis controls for respondent age and health history."
  
- **RAISING THE ALARM** 

  > "The study fails to control for a common cause of diet and heart health: wealth. So the relationship may be spurious, reflecting the fact that wealthy adults are more likely to be vegetarian and, critically, more likely to have healthier hearts independent of their diet."  


---
class: inverse, center, middle

# Designs for Causal Inference


---

# Two modes of large-N study

- **EXPERIMENTAL**
  - Researcher assigns units to treatment at random
  - Researcher observes outcome in response to treatment

- **OBSERVATIONAL**
  - Observer records scores on exposure and outcome
  - 'Passive' data collection


---
class: center, middle

# Experimental design

---

# Experiments

- **Process**
  - Gather subjects; RANDOMIZE into treatment groups
  - Administer treatment
  - Record outcome; evaluate effect  
  
- **Why it works**
  - Randomization! Makes treatment groups identical in expectation
  - Eliminates bias from confounders and reverse causality

- **Flavors of experiments**
  - Field experiments: randomized evaluations (REs) done in the real world (the field)
  - Synthetic experiments: laboratory or survey experiments in a carefully-controlled, artificial environment.
  
  
---
# Experimental example

> *What is the effect of partial vs full cost sharing on bed net usage?* 
>
> In a randomized evaluation, we randomly assigned 900 expecting mothers to receive an incecticide treated bed net at either fully-subsidized or partially-subsidized price. 


```{r plot1,fig.align='center', out.width="50%",dev='svg'}
  df = tribble(~x, ~y,
               "Full subsidy", 65,
               "Partial subsidy", 45)

  ggplot(df, aes(x,y)) + 
    geom_col(fill = 'cornflowerblue',color = 'gray15') +
    scale_y_continuous(
      breaks = seq(0,100,25),
    ) +
    coord_cartesian(ylim = c(0,101)) +
    labs(
      x = "Subsidy",
      y = "Acquired and using ITN",
      title = "ITN usage by subsidy"
    ) +
    theme_bw()
```

---

# What about external validity?

> **External validity** is the extent to which a study's findings generalize to other settings, treatments, outcomes, and populations.

- History and rise of REs
  - Obvious unrealism of "synthetic" experiments
  - Concerns about external validity
  
- REs as potential way forward
  - Study the treatment, outcome, setting of interest
  - But is this more generalizable?
  
- Thinking clearly about experiments
  - Impact-estimating studies: require realism (REs)
  - Theory-testing studies: require abstraction (synthetic)
  

---
class: center, middle

# Observational designs


---

# Observing (not treating)

- **Process**
  - Identify sample
  - Record value on exposure and outcome variables
  - Comparison across groups, conditional on confounds  
  
- **When it works**
  - Strong exogeneity: A way to make exposure to the "treatment" arguably or statistically independent
  - Careful supplemental analyses
  

---

# Observational remake

> *What is the effect of plant-based diet on cholesterol?* 
>
> We surveyed 900 expecting mothers about the price at which they purchased an ITN and their usage of it.  


```{r plot2,fig.align='center', out.width="50%",dev='svg'}
  df = tribble(~x, ~y,
               "Subsidized", 45,
               "Market price", 55)

  ggplot(df, aes(x,y)) + 
    geom_col(fill = 'firebrick3',color = 'gray15') +
    scale_y_continuous(
      breaks = seq(0,100,25),
    ) +
    coord_cartesian(ylim = c(0,101)) +
    labs(
      x = "Subsidy",
      y = "Acquired and using ITN",
      title = "ITN usage by subsidy"
    ) +
    theme_bw()
```

---

# Comparing designs: what gives?

- **With random assignment + control**
  - No systematic differences b/w subjects across groups.
  - Difference in usage attributable to only difference: price  
    &zwnj;  
  
- **With self-selection**
  - Choice to purchase driven by, e.g., wealth, access, etc.
  - Difference in usage attributable to any/all of these things  
    &zwnj;  

Bottom line: the baseline for internal validity is MUCH higher in with an experimental design.


---
class: inverse, center, middle

# Examples from the literature

---

# 1. Cost-sharing and malaria prevention

Cohen and Dupas (2010) "Free distribution or cost-sharing? Evidence from a randomized malaria prevention experiment."

- Causal claim?

- Study design?

- What do we learn from this?


---

# 2. Water fetching and child health

Pickering and Davis (2012) "Freshwater Availability and Water Fetching Distance Affect Child Health in Sub-Saharan Africa."

- Causal claim?

- Study design?

- How do they make fetching distance "exogenous"?

- What do we learn from this?


---
class: center, middle

# Problem Set 3

PS3 is due Wednesday, November 9.

Submit your completed work on Canvas.
